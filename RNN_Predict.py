import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping
from scipy.stats import pearsonr, spearmanr

plt.rcParams['font.family'] = 'Malgun Gothic'
plt.rcParams['axes.unicode_minus'] = False

# ë°ì´í„° ë¡œë“œ
df = pd.read_csv('feat_imp_news_df.csv')
df['date'] = pd.to_datetime(df['date'])
df.set_index('date', inplace=True)

# lag feature ìƒì„± í•¨ìˆ˜
def create_lag_features(df, columns, lags):
    for col in columns:
        for lag in lags:
            df[f'{col}_lag{lag}'] = df[col].shift(lag)
    return df

lag_columns = ['export']
lag_periods = [1, 2, 3, 6, 12]
all_data = create_lag_features(df.copy(), lag_columns, lag_periods)

# íŠ¹ì„± ì»¬ëŸ¼ ì •ì˜
# ì „ì²´ ì»¬ëŸ¼ì—ì„œ ì œì™¸í•  ì»¬ëŸ¼ì„ ì •ì˜
exclude_columns = ['export', 'export_restored']

# ì œì™¸í•œ ë‚˜ë¨¸ì§€ ì»¬ëŸ¼ì„ base_featuresë¡œ ì„¤ì •
base_features = [col for col in df.columns if col not in exclude_columns]

lag_features = [f'export_lag{lag}' for lag in lag_periods]
feature_columns = base_features + lag_features

# ë°ì´í„° ë¶„ë¦¬
train_data = all_data.loc[:'2024-09'].dropna().copy()
test_data = all_data.loc['2024-10':'2025-03'].copy()
combined_data = pd.concat([train_data, test_data]).dropna()

# ì‹œí€€ìŠ¤ ìƒì„± í•¨ìˆ˜
def create_sequences(data, feature_cols, target_col, time_steps=6):
    X, y = [], []
    for i in range(len(data) - time_steps):
        X.append(data[feature_cols].iloc[i:i+time_steps].values)
        y.append(data[target_col].iloc[i+time_steps])
    return np.array(X), np.array(y)

# í•™ìŠµìš© ì‹œí€€ìŠ¤
X_train, y_train = create_sequences(train_data, feature_columns, 'export', time_steps=6)

# ì „ì²´ ì‹œí€€ìŠ¤ì—ì„œ í…ŒìŠ¤íŠ¸ìš© ì‹œí€€ìŠ¤ ë¶„ë¦¬
X_combined, y_combined = create_sequences(combined_data, feature_columns, 'export', time_steps=6)
test_start_idx = combined_data.index.get_loc(pd.to_datetime('2024-10-01'))
test_start_seq_idx = test_start_idx - 6  # ì‹œí€€ìŠ¤ ê¸¸ì´ë§Œí¼ ì•ì—ì„œ ì‹œì‘
X_test = X_combined[test_start_seq_idx:]
y_test = y_combined[test_start_seq_idx:]

# ëª¨ë¸ ì •ì˜
model = Sequential([
    LSTM(64, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True),
    Dropout(0.2),
    LSTM(32, activation='relu'),
    Dropout(0.2),
    Dense(16, activation='relu'),
    Dense(1)
])
model.compile(optimizer='adam', loss='mse', metrics=['mae'])

# ì¡°ê¸° ì¢…ë£Œ ì½œë°±
early_stop = EarlyStopping(monitor='loss', patience=20, restore_best_weights=True)

print("\n=== ëª¨ë¸ í•™ìŠµ ì‹œì‘ ===")
history = model.fit(X_train, y_train, epochs=200, batch_size=32, verbose=1, callbacks=[early_stop])
print("ëª¨ë¸ í•™ìŠµ ì™„ë£Œ")

# ì˜ˆì¸¡
y_pred_scaled = model.predict(X_test).flatten()

# ì—­ì •ê·œí™”ë¥¼ ìœ„í•´ exportì™€ export_restored ë§¤í•‘ 
# LSTMì€ ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”, ê²½ì‚¬í•˜ê°•ë²• ìµœì í™” ê³¼ì •ì—ì„œ ì…ë ¥ê°’ ë²”ìœ„ê°€ ë§¤ìš° ì¤‘ìš” (XGBoost, LightGBM, SARIMAXì™€ ë‹¤ë¥´ê²Œ ëª¨ë¸ ìì²´ê°€ ë°ì´í„° ì „ì²´ë¥¼ ë³´ê³  í•™ìŠµí•˜ê¸° ë•Œë¬¸ì— ë°ì´í„° ì „ì²´ì˜ ë²”ìœ„ê°€ ì¤‘ìš”)
restore_lookup = combined_data['export_restored'].values[6 + test_start_seq_idx:]  # ì‹œí€€ìŠ¤ offset ë³´ì •
scale_lookup = combined_data['export'].values[6 + test_start_seq_idx:]

# í‰ê· , í‘œì¤€í¸ì°¨ ë³µì›ìš© (í‘œì¤€ ì •ê·œí™” ê¸°ì¤€ì¼ ê²½ìš°)
mean_export = df['export_restored'].mean()
std_export = df['export_restored'].std()

# ì—­ì •ê·œí™”: ì˜ˆì¸¡ê°’ë§Œ ì—­ì •ê·œí™”
y_pred = y_pred_scaled * std_export + mean_export
y_true = combined_data['export_restored'].values[6 + test_start_seq_idx:] # ì‹¤ì œê°’ì€ export_restoredì—ì„œ ì§ì ‘ ê°€ì ¸ì˜¤ê¸°
# y_true = y_test * std_export + mean_export // ê¸°ì¡´ y_true ì •í™•ë„ 98í¼ì •ë„ ë‚˜ì˜´ ë‹¤ë§Œë§Œ ìˆ˜ì¶œëŸ‰ì´ ì‹¤ì œì™€ ì¢€ ë‹¤ë¦„

# ê²°ê³¼ ë°ì´í„°í”„ë ˆì„
results_df = pd.DataFrame({
    'date': combined_data.index[6 + test_start_seq_idx:],
    'ì‹¤ì œ ìˆ˜ì¶œì•¡': y_true,
    'ì˜ˆì¸¡ ìˆ˜ì¶œì•¡': y_pred
})
results_df.set_index('date', inplace=True)
results_df['ì˜¤ì°¨ìœ¨(%)'] = ((results_df['ì‹¤ì œ ìˆ˜ì¶œì•¡'] - results_df['ì˜ˆì¸¡ ìˆ˜ì¶œì•¡']) / results_df['ì‹¤ì œ ìˆ˜ì¶œì•¡']) * 100

# í‰ê°€ ì§€í‘œ
mse = mean_squared_error(y_true, y_pred)
rmse = np.sqrt(mse)
mae = mean_absolute_error(y_true, y_pred)
r2 = r2_score(y_true, y_pred)
mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100
accuracy_like = 100 - mape

# ì¶”ì„¸ ìœ ì‚¬ì„±
pearson_corr, _ = pearsonr(y_true, y_pred)
spearman_corr, _ = spearmanr(y_true, y_pred)


print("\n=== ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ ===")
print(f"RMSE: {rmse:,.2f}")
print(f"MAE: {mae:,.2f}")
print(f"R2 Score: {r2:.4f}")
print(f"MAPE: {mape:.2f}%")
print(f"ì˜ˆì¸¡ ì •í™•ë„(ìœ ì‚¬): {accuracy_like:.2f}%")
print(f"ğŸ“ˆ Pearson ìƒê´€ê³„ìˆ˜: {pearson_corr:.4f}")
print(f"ğŸ“ˆ Spearman ìƒê´€ê³„ìˆ˜: {spearman_corr:.4f}")

# ì˜ˆì¸¡ ì¶œë ¥
print("\n=== 2024ë…„ 10ì›”-2025ë…„ 3ì›” ìˆ˜ì¶œì•¡ ì˜ˆì¸¡ ê²°ê³¼ (LSTM) ===")
pd.set_option('display.float_format', lambda x: '{:,.0f}'.format(x) if isinstance(x, (int, float)) else str(x))
print("\n[ë‹¨ìœ„: USD]")
print("=" * 80)
for idx, row in results_df.iterrows():
    print(f"ë‚ ì§œ: {idx.strftime('%Yë…„ %mì›”')}")
    print(f"ì‹¤ì œ ìˆ˜ì¶œì•¡: {row['ì‹¤ì œ ìˆ˜ì¶œì•¡']:>15,.0f}")
    print(f"ì˜ˆì¸¡ ìˆ˜ì¶œì•¡: {row['ì˜ˆì¸¡ ìˆ˜ì¶œì•¡']:>15,.0f}")
    print(f"ì˜¤ì°¨ìœ¨: {row['ì˜¤ì°¨ìœ¨(%)']:>18.2f}%")
    print("-" * 80)
print(f"í‰ê·  ì˜¤ì°¨ìœ¨: {results_df['ì˜¤ì°¨ìœ¨(%)'].mean():>16.2f}%")
print("=" * 80)

# ì‹œê°í™”
plt.figure(figsize=(16, 8))  # ê·¸ë˜í”„ í¬ê¸° ì¢€ ë” í‚¤ì›€

plt.plot(results_df.index, results_df['ì‹¤ì œ ìˆ˜ì¶œì•¡'], label='ì‹¤ì œê°’', marker='o', linewidth=2, markersize=10)
plt.plot(results_df.index, results_df['ì˜ˆì¸¡ ìˆ˜ì¶œì•¡'], label='ì˜ˆì¸¡ê°’', marker='s', linewidth=2, markersize=10)

# ê°’ í‘œì‹œ (annotation) ê¸€ì”¨ í¬ê¸° í‚¤ì›€
for idx, row in results_df.iterrows():
    plt.annotate(f'{row["ì‹¤ì œ ìˆ˜ì¶œì•¡"]:,.0f}', xy=(idx, row["ì‹¤ì œ ìˆ˜ì¶œì•¡"]),
                 xytext=(0, 12), textcoords='offset points', ha='center', va='bottom', fontsize=24, fontweight='bold')
    plt.annotate(f'{row["ì˜ˆì¸¡ ìˆ˜ì¶œì•¡"]:,.0f}', xy=(idx, row["ì˜ˆì¸¡ ìˆ˜ì¶œì•¡"]),
                 xytext=(0, -18), textcoords='offset points', ha='center', va='top', fontsize=24, fontweight='bold')

plt.title('2024ë…„ 10ì›”-2025ë…„ 3ì›” ìˆ˜ì¶œì•¡ ì˜ˆì¸¡ ê²°ê³¼ (ì •ëŸ‰+ì •ì„±)', fontsize=24, fontweight='bold')

plt.legend(fontsize=16)
plt.grid(True)
plt.margins(y=0.2)

# xì¶• ëˆˆê¸ˆ ë¼ë²¨ í¬ê¸° ë° ê°ë„ ì¡°ì ˆ
plt.gca().xaxis.set_major_locator(mdates.MonthLocator(interval=1))
plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))
plt.xticks(rotation=45, fontsize=30)

# yì¶• ëˆˆê¸ˆ ë¼ë²¨ í¬ê¸° ì¡°ì ˆ
plt.yticks(fontsize=14)

plt.tight_layout()
plt.show()

# 2. ì˜¤ì°¨ìœ¨ ê·¸ë˜í”„
plt.subplot(2, 1, 2)
plt.plot(results_df.index, results_df['ì˜¤ì°¨ìœ¨(%)'], color='red', marker='o')
plt.title('ì˜ˆì¸¡ ì˜¤ì°¨ìœ¨ (%)')
plt.xlabel('ë‚ ì§œ')
plt.ylabel('ì˜¤ì°¨ìœ¨ (%)')
plt.grid(True)
plt.gca().xaxis.set_major_locator(mdates.MonthLocator(interval=1))
plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

# ì´ë™í‰ê· ìœ¼ë¡œ ì¶”ì„¸ì„  ì‹œê°í™”
results_df['ì‹¤ì œ_ì´ë™í‰ê· '] = results_df['ì‹¤ì œ ìˆ˜ì¶œì•¡'].rolling(window=2).mean()
results_df['ì˜ˆì¸¡_ì´ë™í‰ê· '] = results_df['ì˜ˆì¸¡ ìˆ˜ì¶œì•¡'].rolling(window=2).mean()

plt.figure(figsize=(10, 6))
plt.plot(results_df.index, results_df['ì‹¤ì œ_ì´ë™í‰ê· '], label='ì‹¤ì œ ì¶”ì„¸ì„ ', linestyle='--')
plt.plot(results_df.index, results_df['ì˜ˆì¸¡_ì´ë™í‰ê· '], label='ì˜ˆì¸¡ ì¶”ì„¸ì„ ', linestyle='--')
plt.legend()
plt.title('ì˜ˆì¸¡ vs ì‹¤ì œ ìˆ˜ì¶œì•¡ ì¶”ì„¸ì„  (ì´ë™í‰ê·  ê¸°ë°˜)')
plt.grid(True)
plt.xticks(rotation=45)
plt.show()

# í•™ìŠµ ì†ì‹¤ ì‹œê°í™”
plt.figure(figsize=(12, 5))
plt.subplot(1, 2, 1)
plt.plot(history.history['loss'])
plt.title('ì†ì‹¤ (Loss)')
plt.xlabel('ì—í¬í¬')
plt.ylabel('Loss')
plt.grid(True)
plt.subplot(1, 2, 2)
plt.plot(history.history['mae'])
plt.title('MAE')
plt.xlabel('ì—í¬í¬')
plt.ylabel('Mean Absolute Error')
plt.grid(True)
plt.tight_layout()
plt.show()
